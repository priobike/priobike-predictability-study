{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of things: 19844\n",
      "Total number of datastreams: 79394\n",
      "Total number of relevant datastreams: 59473\n",
      "Number of datastreams not queried: 49272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8e1fd971774d06abac01d984747e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of things with missing primary signal: 396\n",
      "Number of things with missing cycle second: 141\n",
      "Number of times we skipped cycles because primary signal was missing: 3508\n"
     ]
    }
   ],
   "source": [
    "# Prepare import of modules from parent directory.\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "\n",
    "from studies import np_encoder\n",
    "from preparations import things_provider\n",
    "\n",
    "CSV_FILE = 'observations_example_timerange.csv'\n",
    "\n",
    "def structure_data(csv_file: str) -> dict:\n",
    "    # Parse csv file into pandas dataframe\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Sort by phenonemon_time\n",
    "    df = df.sort_values(by=['phenomenon_time'])\n",
    "\n",
    "    # Directory of things where each thing ID maps to a dict of the three datastream types for that thing\n",
    "    thing_datastreams = {}\n",
    "\n",
    "    # Split dataframe such that we have one dataframe per datastream_id\n",
    "    queried_datastreams = {}\n",
    "    for datastream_id in df['datastream_id'].unique():\n",
    "        queried_datastreams[datastream_id] = df[df['datastream_id'] == datastream_id]\n",
    "        \n",
    "    tp = things_provider.ThingsProvider()\n",
    "    things = tp.get_things()\n",
    "\n",
    "    not_returned_by_db_counter = 0\n",
    "    total_number_of_datastreams = 0\n",
    "    total_number_of_relevant_datastreams = 0\n",
    "\n",
    "    for thing in things:\n",
    "        name = thing['name']\n",
    "        datastreams = thing['Datastreams']\n",
    "        for datastream in datastreams:\n",
    "            total_number_of_datastreams += 1\n",
    "            layer_name = datastream['properties']['layerName']\n",
    "            if layer_name != 'primary_signal' and layer_name != 'cycle_second' and layer_name != 'signal_program':\n",
    "                continue\n",
    "            total_number_of_relevant_datastreams += 1\n",
    "            id = datastream['@iot.id']\n",
    "            if id not in queried_datastreams:\n",
    "                not_returned_by_db_counter += 1\n",
    "                continue\n",
    "            if name not in thing_datastreams:\n",
    "                thing_datastreams[name] = {}\n",
    "            thing_datastreams[name][layer_name] = queried_datastreams[id]\n",
    "\n",
    "    print('Total number of datastreams: ' + str(total_number_of_datastreams))\n",
    "    print('Total number of relevant datastreams: ' + str(total_number_of_relevant_datastreams))\n",
    "    print('Number of datastreams not queried: ' + str(not_returned_by_db_counter))\n",
    "    \n",
    "    return thing_datastreams\n",
    "    \n",
    "def reconstruct_cycles(datastreams: dict):\n",
    "    \"\"\"\n",
    "    datastreams should be a dict with the following structure:\n",
    "    {\n",
    "        \"primary_signal\": pd.DataFrame,\n",
    "        \"cycle_second\": pd.DataFrame,\n",
    "        \"signal_program\": pd.DataFrame\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    primary_signal_missing = False\n",
    "    cycle_second_missing = False\n",
    "    \n",
    "    if 'signal_program' not in datastreams:\n",
    "        signal_programs = None\n",
    "    else:\n",
    "        signal_programs = datastreams['signal_program']\n",
    "    \n",
    "    if 'primary_signal' not in datastreams:\n",
    "        primary_signal_missing = True\n",
    "    if 'cycle_second' not in datastreams:\n",
    "        cycle_second_missing = True\n",
    "    if primary_signal_missing or cycle_second_missing:\n",
    "        return None, primary_signal_missing, cycle_second_missing, signal_programs is None, 0\n",
    "    primary_signals = datastreams['primary_signal']\n",
    "    cycle_seconds = datastreams['cycle_second']\n",
    "    \n",
    "    cycle_seconds_length = len(cycle_seconds)\n",
    "    primary_signals_length = len(primary_signals)\n",
    "    \n",
    "    primary_signal_index = 0\n",
    "    ticker_second = primary_signals.iloc[primary_signal_index]['phenomenon_time']\n",
    "    result = primary_signals.iloc[primary_signal_index]['result']\n",
    "    \n",
    "    if primary_signal_index + 1 >= primary_signals_length:\n",
    "        Exception('Not enough primary signals to reconstruct cycles.')\n",
    "        \n",
    "    upcoming_phenomenon_time = primary_signals.iloc[primary_signal_index + 1]['phenomenon_time']\n",
    "    \n",
    "    programs = {}\n",
    "    cycles = []\n",
    "    current_cycle = None\n",
    "\n",
    "    cycle_second_index = 0\n",
    "    cycle_second_phenonemon_time_start = None\n",
    "    cycle_second_phenonemon_time_end = None\n",
    "    \n",
    "    # How many times we skipped cycles where the primary signal was missing\n",
    "    skipped_cycles = 0\n",
    "    \n",
    "    while ticker_second < cycle_seconds.iloc[-1]['phenomenon_time']:\n",
    "        if cycle_second_index + 1 >= cycle_seconds_length:\n",
    "            # End of data (\"+ 1\") because we also need to have an end for the cycle\n",
    "            break\n",
    "        \n",
    "        # First cycle\n",
    "        if cycle_second_phenonemon_time_start is None:\n",
    "            cycle_second_phenonemon_time_start = cycle_seconds.iloc[cycle_second_index]['phenomenon_time']\n",
    "        if cycle_second_phenonemon_time_end is None:\n",
    "            cycle_second_phenonemon_time_end = cycle_seconds.iloc[cycle_second_index + 1]['phenomenon_time']\n",
    "        \n",
    "        # Next cycle:\n",
    "        if ticker_second >= cycle_second_phenonemon_time_end:\n",
    "            if current_cycle is None:\n",
    "                skipped_cycles += 1\n",
    "            else:\n",
    "                # Save current cycle\n",
    "                cycles.append(current_cycle)\n",
    "                current_cycle = None\n",
    "            \n",
    "            cycle_second_index += 1\n",
    "            cycle_second_phenonemon_time_start = cycle_seconds.iloc[cycle_second_index]['phenomenon_time']\n",
    "            cycle_second_phenonemon_time_end = cycle_seconds.iloc[cycle_second_index + 1]['phenomenon_time']\n",
    "        \n",
    "        if upcoming_phenomenon_time is not None and ticker_second >= upcoming_phenomenon_time:\n",
    "            primary_signal_index += 1\n",
    "            result = primary_signals.iloc[primary_signal_index]['result']\n",
    "            if primary_signal_index + 1 >= primary_signals_length:\n",
    "                upcoming_phenomenon_time = None\n",
    "            else:\n",
    "                upcoming_phenomenon_time = primary_signals.iloc[primary_signal_index + 1]['phenomenon_time']\n",
    "            \n",
    "        if current_cycle is None and ticker_second == cycle_second_phenonemon_time_start:\n",
    "            current_cycle = {\n",
    "                'start': cycle_second_phenonemon_time_start,\n",
    "                'end': cycle_second_phenonemon_time_end,\n",
    "                'results': []\n",
    "            }\n",
    "        \n",
    "        if current_cycle is not None and ticker_second >= cycle_second_phenonemon_time_start:\n",
    "            if upcoming_phenomenon_time is None:\n",
    "                diff_upcoming = 999_999_999_999\n",
    "            else:\n",
    "                diff_upcoming = upcoming_phenomenon_time - ticker_second\n",
    "                \n",
    "            diff_cycle_end = cycle_second_phenonemon_time_end - ticker_second\n",
    "            \n",
    "            diff = min(diff_upcoming, diff_cycle_end)\n",
    "            results_to_append = [result] * diff\n",
    "            \n",
    "            current_cycle['results'].extend(results_to_append)\n",
    "    \n",
    "            ticker_second += diff\n",
    "            \n",
    "        else:\n",
    "            ticker_second += 1\n",
    "        \n",
    "    UNKNWON_PROGRAM_IDENTIFIER = 'unknown'\n",
    "        \n",
    "    if signal_programs is None or len(signal_programs) == 0:\n",
    "        programs = {\n",
    "            UNKNWON_PROGRAM_IDENTIFIER: cycles\n",
    "        }\n",
    "    else:\n",
    "        current_program = UNKNWON_PROGRAM_IDENTIFIER\n",
    "        signal_program_index = 0\n",
    "        signal_program_phenomenon_time_start = None\n",
    "        signal_program_phenomenon_time_end = None\n",
    "        for cycle in cycles:\n",
    "            # First program:\n",
    "            if signal_program_phenomenon_time_start is None and signal_program_index < len(signal_programs):\n",
    "                signal_program_phenomenon_time_start = signal_programs.iloc[signal_program_index]['phenomenon_time']\n",
    "                current_program = str(signal_programs.iloc[signal_program_index]['result'])\n",
    "            if signal_program_phenomenon_time_end is None and signal_program_index + 1 < len(signal_programs):\n",
    "                signal_program_phenomenon_time_end = signal_programs.iloc[signal_program_index + 1]['phenomenon_time']\n",
    "                \n",
    "            # Next program:\n",
    "            if signal_program_phenomenon_time_end is not None and cycle['start'] >= signal_program_phenomenon_time_end:\n",
    "                signal_program_index += 1\n",
    "                if signal_program_index < len(signal_programs):\n",
    "                    signal_program_phenomenon_time_start = signal_programs.iloc[signal_program_index]['phenomenon_time']\n",
    "                    current_program = str(signal_programs.iloc[signal_program_index]['result'])\n",
    "                else:\n",
    "                    signal_program_phenomenon_time_start = None\n",
    "                    current_program = UNKNWON_PROGRAM_IDENTIFIER\n",
    "                if signal_program_index + 1 < len(signal_programs):\n",
    "                    signal_program_phenomenon_time_end = signal_programs.iloc[signal_program_index + 1]['phenomenon_time']\n",
    "                else:   \n",
    "                    signal_program_phenomenon_time_end = None\n",
    "                    \n",
    "            if cycle['start'] < signal_program_phenomenon_time_start and cycle['end'] > signal_program_phenomenon_time_start:\n",
    "                # Cycle starts before new program starts and ends after new program starts (something wrong in data).\n",
    "                continue\n",
    "                \n",
    "            if current_program not in programs:\n",
    "                programs[current_program] = []\n",
    "                \n",
    "            programs[current_program].append(cycle)\n",
    "    \n",
    "    return programs, primary_signal_missing, cycle_second_missing, signal_programs is None, skipped_cycles\n",
    "\n",
    "    \n",
    "datastreams_per_thing = structure_data(CSV_FILE)\n",
    "    \n",
    "# Directory of things where each thing ID maps to a list of programs with cycles for that thing\n",
    "thing_cycles = {}\n",
    "\n",
    "primary_signal_missing_count = 0\n",
    "cycle_second_missing_count = 0\n",
    "signal_program_missing_count = 0\n",
    "\n",
    "total_skipped_cycles = 0\n",
    "\n",
    "for thing in tqdm(datastreams_per_thing):\n",
    "    datastreams = datastreams_per_thing[thing]\n",
    "    programs, primary_signal_missing, cycle_second_missing, signal_program_missing, skipped_cycles = reconstruct_cycles(datastreams)\n",
    "    total_skipped_cycles += skipped_cycles\n",
    "    if primary_signal_missing:\n",
    "        primary_signal_missing_count += 1\n",
    "    if cycle_second_missing:\n",
    "        cycle_second_missing_count += 1\n",
    "    if signal_program_missing:\n",
    "        signal_program_missing_count += 1\n",
    "    if programs is None:\n",
    "        continue\n",
    "\n",
    "    thing_cycles[thing] = programs\n",
    "\n",
    "with open('observations_example_timerange_reconstructed_cycles.json', 'w') as f:\n",
    "    json.dump(thing_cycles, f, indent=4, cls=np_encoder.NpEncoder)\n",
    "    \n",
    "print('Number of things with missing primary signal: ' + str(primary_signal_missing_count))\n",
    "print('Number of things with missing cycle second: ' + str(cycle_second_missing_count))\n",
    "print('Number of times we skipped cycles because primary signal was missing: ' + str(total_skipped_cycles))\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
